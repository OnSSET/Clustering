{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "import fiona\n",
    "import rasterio.mask\n",
    "from rasterio.fill import fillnodata\n",
    "from rasterstats import zonal_stats\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "import rasterio\n",
    "import json\n",
    "import pandas as pd\n",
    "from osgeo import gdal, ogr, osr\n",
    "\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "root.attributes(\"-topmost\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ClipRasterByExtent(raster, admin, workspace):\n",
    "    bbox = admin.total_bounds\n",
    "    bbox2 = [bbox[0], bbox[3], bbox[2], bbox[1]]\n",
    "    clipped = gdal.Translate('', raster, format = 'MEM', projWin = bbox2, noData = 0)\n",
    "    return clipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reclassify raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ReclassifyRasters(file):    \n",
    "    driver = gdal.GetDriverByName(\"MEM\")\n",
    "    band = file.GetRasterBand(1)\n",
    "    lista = band.ReadAsArray()\n",
    "    \n",
    "    lista[np.where((0 < lista) & (lista < 999999999))] = 1\n",
    "\n",
    "    file2 = driver.Create('', file.RasterXSize , file.RasterYSize , 1, gdal.GDT_Float32)\n",
    "    file2.GetRasterBand(1).WriteArray(lista)\n",
    "\n",
    "    proj = file.GetProjection()\n",
    "    georef = file.GetGeoTransform()\n",
    "    file2.SetProjection(proj)\n",
    "    file2.SetGeoTransform(georef)\n",
    "    file2.FlushCache()\n",
    "    \n",
    "    return file2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ResampleRaster(raster, factor):\n",
    "    gt =raster.GetGeoTransform()\n",
    "    xRes = factor*gt[1]\n",
    "    yRes = factor*gt[1]\n",
    "    kwargs1 = {'noData':'0'}\n",
    "    resamp1 = gdal.Translate('',raster, format ='MEM', **kwargs1)\n",
    "    kwargs2 = {'xRes': xRes, 'yRes': yRes, 'resampleAlg':'mode'}    \n",
    "    resampled = gdal.Translate('',resamp1, format ='MEM', noData = 0, **kwargs2)\n",
    "    \n",
    "    return resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rasterize Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rasterize(vector, vector_path, raster, output):\n",
    "    \n",
    "    vector[\"id\"] = np.arange(len(vector))+1\n",
    "    vector.to_file(vector_path)\n",
    "    data = raster\n",
    "\n",
    "    geo_transform = data.GetGeoTransform()\n",
    "    x_min = geo_transform[0]\n",
    "    y_max = geo_transform[3]\n",
    "    x_max = x_min + geo_transform[1] * data.RasterXSize\n",
    "    y_min = y_max + geo_transform[5] * data.RasterYSize\n",
    "    x_res = data.RasterXSize\n",
    "    y_res = data.RasterYSize\n",
    "    mb_v = ogr.Open(vector_path)\n",
    "    mb_l = mb_v.GetLayer()\n",
    "    pixel_width = geo_transform[1]\n",
    "    target_ds = gdal.GetDriverByName('GTiff').Create(output, x_res, y_res, 1, gdal.GDT_Byte)\n",
    "    target_ds.SetGeoTransform((x_min, pixel_width, 0, y_max, 0, -pixel_width))\n",
    "    target_dsSRS = osr.SpatialReference()\n",
    "    target_dsSRS.ImportFromEPSG(4326)\n",
    "    target_ds.SetProjection(target_dsSRS.ExportToWkt())\n",
    "    band = target_ds.GetRasterBand(1)\n",
    "    NoData_value = -999999\n",
    "    band.SetNoDataValue(NoData_value)\n",
    "    band.FlushCache()\n",
    "    gdal.RasterizeLayer(target_ds, [1], mb_l, options=[\"ATTRIBUTE=id\"])\n",
    "    target_ds = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rastercalculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def array_calc(rstpth1,rstpth2, output, filetype = gdal.GDT_Float32):\n",
    "    \n",
    "    rst1 = gdal.Open(rstpth1)\n",
    "    band_data1 = rst1.GetRasterBand(1)\n",
    "    a = band_data1.ReadAsArray()\n",
    "\n",
    "    rst2 = gdal.Open(rstpth2)\n",
    "    band_data2 = rst2.GetRasterBand(1)\n",
    "    b = band_data2.ReadAsArray()\n",
    "    \n",
    "    f = b * a\n",
    "        \n",
    "    ref = gdal.Open(rstpth1)\n",
    "    band = ref.GetRasterBand(1)\n",
    "    proj = ref.GetProjection()\n",
    "    geotransform = ref.GetGeoTransform()\n",
    "    xsize = band.XSize\n",
    "    ysize = band.YSize\n",
    "    \n",
    "    driver = gdal.GetDriverByName('GTiff') \n",
    "    out = driver.Create(output, xsize, ysize, 1, filetype)\n",
    "    out.GetRasterBand(1).WriteArray(f) \n",
    "    \n",
    "    out.SetProjection(proj)\n",
    "    out.SetGeoTransform(geotransform)\n",
    "    out.FlushCache()\n",
    "    out = None\n",
    "    x = gdal.Open(output)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Urban/rural split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CalibrateUrban(clusters, urban_current, workspace):      \n",
    "    \n",
    "    urban_modelled = 2\n",
    "    factor = 1\n",
    "    pop_tot = clusters[\"Popsum\"].sum()\n",
    "    \n",
    "    while abs(urban_modelled - urban_current) > 0.001:\n",
    "        clusters[\"IsUrban\"] = 0\n",
    "        \n",
    "        clusters.loc[(clusters[\"Popsum\"] > 5000 * factor) & (\n",
    "            clusters[\"Popsum\"] / clusters[\"GridCellAr\"] > 350 * factor), \"IsUrban\"] = 1\n",
    "        clusters.loc[(clusters[\"Popsum\"] > 50000 * factor) & (\n",
    "            clusters[\"Popsum\"] / clusters[\"GridCellAr\"] > 1500 * factor), \"IsUrban\"] = 2\n",
    "        pop_urb = clusters.loc[clusters[\"IsUrban\"] > 1, \"Popsum\"].sum()\n",
    "        \n",
    "        urban_modelled = pop_urb / pop_tot\n",
    "        \n",
    "        if urban_modelled > urban_current:\n",
    "            factor *= 1.1\n",
    "        else:\n",
    "            factor *= 0.9\n",
    "            \n",
    "    clusters.to_file(workspace + r\"/clusters.shp\") \n",
    "    \n",
    "    print(\"modelled urban ratio is \" + str(urban_modelled) + \"% in comparision to the actual ratio of \" + str(urban_current) + \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert raster to polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ToPolygon(Raster, opt, output):\n",
    "    \n",
    "    if type(Raster) == str:\n",
    "        Raster = gdal.Open(Raster)\n",
    "    \n",
    "    band = Raster.GetRasterBand(1)\n",
    "    bandArray = band.ReadAsArray()\n",
    "    \n",
    "    outShapefile = output\n",
    "    \n",
    "    driver = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
    "    if os.path.exists(outShapefile+\".shp\"):\n",
    "        driver.DeleteDataSource(outShapefile+\".shp\")\n",
    "    outDatasource = driver.CreateDataSource(outShapefile+ \".shp\")\n",
    "    \n",
    "    outLayer = outDatasource.CreateLayer(outShapefile+ \".shp\", srs=None)\n",
    "    newField = ogr.FieldDefn('PLACEHOLDE', ogr.OFTInteger)\n",
    "    outLayer.CreateField(newField)\n",
    "    gdal.Polygonize(band, band, outLayer, 0, [\"8CONNECTED=8\",\"GROUPBY=PLACEHOLDE\"], callback=None)\n",
    "    outDatasource.Destroy()\n",
    "    sourceRaster = None\n",
    "    if opt ==1:\n",
    "        out = gpd.read_file(outShapefile+\".shp\")\n",
    "    else:\n",
    "        NTLArea=gpd.read_file(outShapefile+\".shp\")\n",
    "        clean = NTLArea[NTLArea.PLACEHOLDE != 0]\n",
    "        clean_b = clean.buffer(0)\n",
    "        clean_b.crs = {'init' :'epsg:4326'}\n",
    "        out = clean_b\n",
    "        out = clean_b\n",
    "    \n",
    "    return out      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip raster by mask and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ClipRasterByMask(raster_path, mask_path, crs, output):\n",
    "    with fiona.open(mask_path, \"r\") as shapefile:\n",
    "        shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        out_image, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n",
    "        out_image[out_image<0] = np.nan\n",
    "        mask = (out_image!=0)\n",
    "        out_image = fillnodata(out_image, mask)\n",
    "        out_meta = src.meta\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "                     \"height\": out_image.shape[1],\n",
    "                     \"width\": out_image.shape[2],\n",
    "                     \"transform\": out_transform,\n",
    "                     \"crs\": crs})\n",
    "    \n",
    "    out_meta.update(compress = 'lzw')\n",
    "    \n",
    "    with rasterio.open(output, \"w\", **out_meta) as dest:\n",
    "        dest.write(out_image)\n",
    "    out = rasterio.open(output)\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save memory raster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveRaster(input_file, output_file):\n",
    "    kwargs = {'creationOptions': ['COMPRESS=LZW']}\n",
    "    gdal.Warp(output_file, input_file, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting and populating clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addAttributes(clusters, crs, country_name):\n",
    "    clusters['id'] = np.arange(len(clusters))\n",
    "    clusters.crs = {'init' :'epsg:4326'}\n",
    "    clusters_proj = clusters.to_crs({ 'init': crs})\n",
    "    clusters_proj[\"GridCellAr\"] = clusters_proj.area/1000000\n",
    "    clusters_proj[\"Country\"] = country_name\n",
    "    clusters = clusters_proj.to_crs({ 'init': 'epsg:4326'})\n",
    "    clusters = clusters.drop(['PLACEHOLDE'], axis=1)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def populatingClusters(clusters,raster,column,method):\n",
    "    clusters = zonal_stats(\n",
    "    clusters,\n",
    "    raster.name,\n",
    "    stats=[method],\n",
    "    prefix=column, geojson_out=True, all_touched=True)\n",
    "    \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalizing clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def finalizing_clusters(clusters, workspace):\n",
    "    output = workspace + r'\\placeholder.geojson'\n",
    "    with open(output, \"w\") as dst:\n",
    "        collection = {\n",
    "            \"type\": \"FeatureCollection\",\n",
    "            \"features\": list(clusters)}\n",
    "        dst.write(json.dumps(collection))\n",
    "  \n",
    "    clusters = gpd.read_file(output)\n",
    "    clusters.fillna(0, inplace=True)\n",
    "    os.remove(output)\n",
    "    \n",
    "    clusters = clusters.rename(columns={\"popsum\": \"Pop\"})\n",
    "    clusters = clusters.rename(columns={\"NTLmax\": \"NightLight\"})\n",
    "    clusters = clusters.rename(columns={\"area\": \"Area\"})\n",
    "    clusters = clusters.rename(columns={\"ElecPopsum\": \"ElecPop\"})\n",
    "    \n",
    "    clusters.to_file(workspace + r\"\\clusters.shp\")\n",
    "\n",
    "    dir_name = workspace\n",
    "    test = os.listdir(dir_name)\n",
    "\n",
    "    for item in test:\n",
    "        if item.endswith(\".tif\") or item.startswith(\"NTLArea\") or item.startswith(\"bufferedlines\"):\n",
    "            os.remove(os.path.join(dir_name, item))\n",
    "            \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
